{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlgpMZW04VdR4CVdIWj6Ro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayannaavalos/166/blob/main/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EmaWODzaa8op",
        "outputId": "b4436f95-5375-422c-893f-755977465bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.12/dist-packages/AutoROM/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \"gymnasium[atari]\" autorom stable-baselines3 torch tensorboard imageio imageio-ffmpeg\n",
        "!AutoROM --accept-license"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, glob, collections, typing as tt\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import ale_py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common import atari_wrappers\n",
        "from IPython.display import Video, display"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HxHt8Bp5bP8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Configuration\n",
        "DEFAULT_ENV_NAME = \"ALE/SpaceInvaders-v5\"\n",
        "MEAN_REWARD_BOUND = 10_000\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 50_000\n",
        "LEARNING_RATE = 1e-4\n",
        "SYNC_TARGET_FRAMES = 1_000\n",
        "REPLAY_START_SIZE = 2_000\n",
        "\n",
        "SAVE_EPSILON = 0.5  # Only save if at least this much better\n",
        "EPSILON_DECAY_LAST_FRAME = 50_000\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_FINAL = 0.05\n",
        "\n",
        "\n",
        "CLIP_REWARD = True\n",
        "\n",
        "EARLY_EPISODES_TO_RECORD = 1\n",
        "\n",
        "LATE_THRESHOLD = -19.0\n",
        "LATE_AFTER_FRAMES = 12_000\n",
        "LATE_EPISODES_TO_RECORD = 1"
      ],
      "metadata": {
        "id": "3CjOGmtcjj7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    \"\"\"(H, W, C) -> (C, H, W) for PyTorch convs.\"\"\"\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs = self.observation_space\n",
        "        assert isinstance(obs, gym.spaces.Box) and len(obs.shape) == 3\n",
        "        new_shape = (obs.shape[-1], obs.shape[0], obs.shape[1])\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=obs.low.min(), high=obs.high.max(),\n",
        "            shape=new_shape, dtype=obs.dtype\n",
        "        )\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    \"\"\"Stack the last n_steps frames along channel axis.\"\"\"\n",
        "    def __init__(self, env, n_steps):\n",
        "        super().__init__(env)\n",
        "        obs = env.observation_space\n",
        "        assert isinstance(obs, spaces.Box)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            obs.low.repeat(n_steps, axis=0),\n",
        "            obs.high.repeat(n_steps, axis=0),\n",
        "            dtype=obs.dtype\n",
        "        )\n",
        "        self.buffer = collections.deque(maxlen=n_steps)\n",
        "\n",
        "    def reset(self, *, seed: tt.Optional[int] = None, options: tt.Optional[dict] = None):\n",
        "        for _ in range(self.buffer.maxlen):\n",
        "            self.buffer.append(np.zeros_like(self.env.observation_space.low))\n",
        "        obs, info = self.env.reset(seed=seed, options=options)\n",
        "        return self.observation(obs), info\n",
        "\n",
        "    def observation(self, observation: np.ndarray) -> np.ndarray:\n",
        "        self.buffer.append(observation)\n",
        "        return np.concatenate(self.buffer)\n",
        "\n",
        "\n",
        "def make_env(env_name: str, n_steps=4, render_mode=None, **kwargs):\n",
        "    print(f\"Creating environment {env_name}\")\n",
        "    env = gym.make(env_name, render_mode=render_mode, **kwargs)\n",
        "    env = atari_wrappers.AtariWrapper(\n",
        "        env,\n",
        "        clip_reward=bool(globals().get(\"CLIP_REWARD\", False)),\n",
        "        noop_max=30\n",
        "    )\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, n_steps=n_steps)\n",
        "    return env"
      ],
      "metadata": {
        "id": "GpRmMgD5bSGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        size = self.conv(torch.zeros(1, *input_shape)).size(-1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.ByteTensor):\n",
        "        x = x.float() / 255.0\n",
        "        return self.fc(self.conv(x))\n"
      ],
      "metadata": {
        "id": "cvetzztBbU0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "State = np.ndarray\n",
        "Action = int\n",
        "\n",
        "@dataclass\n",
        "class Experience:\n",
        "    state: State\n",
        "    action: Action\n",
        "    reward: float\n",
        "    done_trunc: bool\n",
        "    new_state: State\n",
        "\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "    def __len__(self): return len(self.buffer)\n",
        "    def append(self, experience: Experience): self.buffer.append(experience)\n",
        "    def sample(self, batch_size: int) -> tt.List[Experience]:\n",
        "        idxs = np.random.choice(len(self), batch_size, replace=False)\n",
        "        return [self.buffer[i] for i in idxs]\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, env: gym.Env, exp_buffer: ExperienceBuffer):\n",
        "        self.env = env\n",
        "        self.exp_buffer = exp_buffer\n",
        "        self.state, _ = self.env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def play_step(self, net: DQN, device: torch.device, epsilon: float = 0.0) -> tt.Optional[float]:\n",
        "        if np.random.random() < epsilon:\n",
        "            action = self.env.action_space.sample()\n",
        "        else:\n",
        "            state_v = torch.as_tensor(self.state, device=device).unsqueeze(0)\n",
        "            q_vals_v = net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "        new_state, reward, is_done, is_tr, _ = self.env.step(action)\n",
        "        self.total_reward += reward\n",
        "\n",
        "        self.exp_buffer.append(Experience(\n",
        "            state=self.state, action=action, reward=float(reward),\n",
        "            done_trunc=(is_done or is_tr), new_state=new_state\n",
        "        ))\n",
        "        self.state = new_state\n",
        "\n",
        "        if is_done or is_tr:\n",
        "            done_reward = self.total_reward\n",
        "            self.state, _ = self.env.reset()\n",
        "            self.total_reward = 0.0\n",
        "            return done_reward\n",
        "        return None"
      ],
      "metadata": {
        "id": "fG7LZLL1bWpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_tensors(batch: tt.List[Experience], device: torch.device):\n",
        "    states, actions, rewards, dones, new_states = [], [], [], [], []\n",
        "    for e in batch:\n",
        "        states.append(e.state)\n",
        "        actions.append(e.action)\n",
        "        rewards.append(e.reward)\n",
        "        dones.append(e.done_trunc)\n",
        "        new_states.append(e.new_state)\n",
        "\n",
        "    states_t = torch.as_tensor(np.asarray(states), device=device)\n",
        "    actions_t = torch.as_tensor(actions, dtype=torch.long, device=device)\n",
        "    rewards_t = torch.as_tensor(rewards, dtype=torch.float32, device=device)\n",
        "    dones_t = torch.as_tensor(dones, dtype=torch.bool, device=device)\n",
        "    new_states_t = torch.as_tensor(np.asarray(new_states), device=device)\n",
        "    return states_t, actions_t, rewards_t, dones_t, new_states_t\n",
        "\n",
        "\n",
        "def calc_loss(batch: tt.List[Experience], net: DQN, tgt_net: DQN, device: torch.device) -> torch.Tensor:\n",
        "    states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n",
        "    state_action_values = net(states_t).gather(1, actions_t.unsqueeze(-1)).squeeze(-1)\n",
        "    with torch.no_grad():\n",
        "        next_state_values = tgt_net(new_states_t).max(1)[0]\n",
        "        next_state_values[dones_t] = 0.0\n",
        "    expected_state_action_values = rewards_t + GAMMA * next_state_values\n",
        "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
      ],
      "metadata": {
        "id": "zcA7r0IjbaMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_GOOGLE_DRIVE = True\n",
        "\n",
        "save_dir_drive = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "save_dir_local = \"saved_models\"\n",
        "env_name = DEFAULT_ENV_NAME\n",
        "safe_env_name = env_name.replace(\"/\", \"_\")\n",
        "\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.makedirs(save_dir_drive, exist_ok=True)\n",
        "\n",
        "os.makedirs(save_dir_local, exist_ok=True)\n",
        "\n",
        "print(\"Saving to:\")\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    print(\" - Google Drive:\", save_dir_drive)\n",
        "print(\" - Local       :\", save_dir_local)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBVLb99Nbatj",
        "outputId": "1fd0207a-191b-4186-8047-46f418fb60f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saving to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models\n",
            " - Local       : saved_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_recording_env(env_name: str, video_folder: str, name_prefix: str, n_steps: int = 4):\n",
        "    os.makedirs(video_folder, exist_ok=True)\n",
        "    base = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    wrapped = atari_wrappers.AtariWrapper(\n",
        "        base,\n",
        "        clip_reward=bool(globals().get(\"CLIP_REWARD\", False)),\n",
        "        noop_max=30,\n",
        "        terminal_on_life_loss=True\n",
        "    )\n",
        "    wrapped = ImageToPyTorch(wrapped)\n",
        "    wrapped = BufferWrapper(wrapped, n_steps=n_steps)\n",
        "    rec = gym.wrappers.RecordVideo(\n",
        "        wrapped,\n",
        "        video_folder=video_folder,\n",
        "        name_prefix=name_prefix,\n",
        "        episode_trigger=lambda ep_idx: True,\n",
        "    )\n",
        "    return rec\n",
        "\n",
        "@torch.no_grad()\n",
        "def record_episodes_with(\n",
        "    net: DQN,\n",
        "    env_name: str,\n",
        "    video_folder: str,\n",
        "    name_prefix: str,\n",
        "    episodes: int = 1,\n",
        "    epsilon: float = 0.05,\n",
        "    max_steps: int | None = None,   # NEW: hard cap per episode (e.g., 1200 frames)\n",
        "):\n",
        "    env = make_recording_env(env_name, video_folder, name_prefix)\n",
        "    device = next(net.parameters()).device\n",
        "    vids = []\n",
        "    for ep in range(episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = trunc = False\n",
        "        ep_ret = 0.0\n",
        "        steps = 0\n",
        "        while not (done or trunc):\n",
        "            # Îµ-greedy policy (Îµ=1.0 -> random)\n",
        "            if np.random.random() < epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                q = net(torch.as_tensor(obs, device=device).unsqueeze(0))\n",
        "                action = int(torch.argmax(q, dim=1).item())\n",
        "\n",
        "            obs, r, done, trunc, _ = env.step(action)\n",
        "            ep_ret += float(r)\n",
        "            steps += 1\n",
        "\n",
        "            if (max_steps is not None) and (steps >= max_steps):   # NEW: short clips\n",
        "                break\n",
        "\n",
        "        print(f\"[{name_prefix}] episode={ep} return={ep_ret:.1f} steps={steps}\")\n",
        "\n",
        "    env.close()\n",
        "    vids = sorted(glob.glob(os.path.join(video_folder, f\"{name_prefix}*.mp4\")))\n",
        "    return vids\n",
        "\n",
        "def record_late_clip_quick(net):\n",
        "    return record_episodes_with(\n",
        "        net=net,\n",
        "        env_name=DEFAULT_ENV_NAME,\n",
        "        video_folder=\"videos_late_quick\",\n",
        "        name_prefix=\"late_quick\",\n",
        "        episodes=LATE_EPISODES_TO_RECORD,   # usually 3\n",
        "        epsilon=0.05                         # almost greedy\n",
        "    )\n",
        "\n",
        "def show_videos(video_paths):\n",
        "    for vp in video_paths:\n",
        "        print(\"ðŸ“¹\", vp)\n",
        "        display(Video(vp, embed=True, html_attributes=\"controls\"))\n"
      ],
      "metadata": {
        "id": "RaNJ-6DkoIaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_comment = f\"test_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_sync{SYNC_TARGET_FRAMES}\"\n",
        "\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
        "print(net)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "total_rewards = []\n",
        "frame_idx = 0\n",
        "ts_frame = 0\n",
        "ts = time.time()\n",
        "best_m_reward = None\n",
        "start_time = time.time()\n",
        "\n",
        "# Flags to auto-capture videos\n",
        "captured_early = False\n",
        "captured_late  = False\n",
        "LATE_THRESHOLD = 0.0  # set to -5.0  to record sooner\n",
        "\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "    if reward is not None:\n",
        "        total_rewards.append(reward)\n",
        "        speed = (frame_idx - ts_frame) / (time.time() - ts + 1e-8)\n",
        "        elapsed = time.time() - start_time  # seconds\n",
        "        ts_frame = frame_idx\n",
        "        ts = time.time()\n",
        "        m_reward = float(np.mean(total_rewards[-100:]))\n",
        "\n",
        "        print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "\n",
        "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
        "            model_path_local = os.path.join(save_dir_local, model_filename)\n",
        "            torch.save(net.state_dict(), model_path_local)\n",
        "\n",
        "            if USE_GOOGLE_DRIVE:\n",
        "                model_path_drive = os.path.join(save_dir_drive, model_filename)\n",
        "                torch.save(net.state_dict(), model_path_drive)\n",
        "                print(\"ðŸ’¾ Model saved to:\")\n",
        "                print(\" - Google Drive:\", model_path_drive)\n",
        "                print(\" - Local:        \", model_path_local)\n",
        "            else:\n",
        "                print(\"ðŸ’¾ Model saved to:\")\n",
        "                print(\" - Local:        \", model_path_local)\n",
        "\n",
        "            if best_m_reward is not None:\n",
        "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
        "            best_m_reward = m_reward\n",
        "\n",
        "            if (not captured_early) and (frame_idx >= 5):\n",
        "              early_vids = record_episodes_with(\n",
        "                  net=net,\n",
        "                  env_name=DEFAULT_ENV_NAME,\n",
        "                  video_folder=\"videos_early\",\n",
        "                  name_prefix=f\"early_f{frame_idx:06d}\",  # unique + sortable\n",
        "                  episodes=EARLY_EPISODES_TO_RECORD,\n",
        "                  epsilon=1.0,                            # very bad / random-ish\n",
        "                  max_steps=400               # small file\n",
        "              )\n",
        "              if early_vids:\n",
        "                  print(f\"EARLY videos @ frame {frame_idx}:\", early_vids)\n",
        "              captured_early = True\n",
        "\n",
        "        # Auto-record LATE once when performance reaches threshold\n",
        "        if (not captured_late) and ( (m_reward >= LATE_THRESHOLD) or (frame_idx >= LATE_AFTER_FRAMES) ):\n",
        "          late_vids = record_late_clip_quick(net)\n",
        "          if late_vids:\n",
        "              print(\"LATE video:\", late_vids[-1])\n",
        "          captured_late = True\n",
        "\n",
        "        if m_reward > MEAN_REWARD_BOUND:\n",
        "            print(\"Solved in %d frames!\" % frame_idx)\n",
        "            break\n",
        "\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        continue\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "env.close()\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q78AoS21beAL",
        "outputId": "52c06284-b51d-4ef6-c16a-69792b86cc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/SpaceInvaders-v5\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "28: done 1 games, reward 1.000, eps 1.00, speed 79.97 f/s, time 0.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_SpaceInvaders-v5-best_1-20250929-0021-test_epsdec50000_rs2000_sync1000.dat\n",
            " - Local:         saved_models/ALE_SpaceInvaders-v5-best_1-20250929-0021-test_epsdec50000_rs2000_sync1000.dat\n",
            "[early_f000028] episode=0 return=0.0 steps=29\n",
            "EARLY videos @ frame 28: ['videos_early/early_f000028-episode-0.mp4']\n",
            "[late_quick] episode=0 return=2.0 steps=41\n",
            "LATE video: videos_late_quick/late_quick-episode-0.mp4\n",
            "44: done 2 games, reward 1.500, eps 1.00, speed 4.95 f/s, time 0.1 min\n",
            "105: done 3 games, reward 2.667, eps 1.00, speed 193.11 f/s, time 0.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_SpaceInvaders-v5-best_2-20250929-0021-test_epsdec50000_rs2000_sync1000.dat\n",
            " - Local:         saved_models/ALE_SpaceInvaders-v5-best_2-20250929-0021-test_epsdec50000_rs2000_sync1000.dat\n",
            "Best reward updated 1.000 -> 2.667\n",
            "151: done 4 games, reward 2.500, eps 1.00, speed 202.72 f/s, time 0.1 min\n",
            "173: done 5 games, reward 2.200, eps 1.00, speed 341.29 f/s, time 0.1 min\n",
            "237: done 6 games, reward 2.500, eps 1.00, speed 320.67 f/s, time 0.1 min\n",
            "274: done 7 games, reward 3.286, eps 0.99, speed 307.10 f/s, time 0.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_SpaceInvaders-v5-best_3-20250929-0021-test_epsdec50000_rs2000_sync1000.dat\n",
            " - Local:         saved_models/ALE_SpaceInvaders-v5-best_3-20250929-0021-test_epsdec50000_rs2000_sync1000.dat\n",
            "Best reward updated 2.667 -> 3.286\n",
            "310: done 8 games, reward 3.125, eps 0.99, speed 277.85 f/s, time 0.1 min\n",
            "345: done 9 games, reward 3.111, eps 0.99, speed 311.96 f/s, time 0.1 min\n",
            "380: done 10 games, reward 3.000, eps 0.99, speed 351.63 f/s, time 0.1 min\n",
            "393: done 11 games, reward 2.727, eps 0.99, speed 307.67 f/s, time 0.1 min\n",
            "511: done 12 games, reward 3.417, eps 0.99, speed 359.18 f/s, time 0.1 min\n",
            "530: done 13 games, reward 3.154, eps 0.99, speed 324.87 f/s, time 0.1 min\n",
            "558: done 14 games, reward 3.214, eps 0.99, speed 359.18 f/s, time 0.1 min\n",
            "572: done 15 games, reward 3.000, eps 0.99, speed 235.94 f/s, time 0.1 min\n",
            "607: done 16 games, reward 3.125, eps 0.99, speed 310.06 f/s, time 0.1 min\n",
            "671: done 17 games, reward 3.176, eps 0.99, speed 372.10 f/s, time 0.1 min\n",
            "710: done 18 games, reward 3.111, eps 0.99, speed 303.12 f/s, time 0.1 min\n",
            "725: done 19 games, reward 3.000, eps 0.99, speed 310.79 f/s, time 0.1 min\n",
            "761: done 20 games, reward 3.000, eps 0.98, speed 351.07 f/s, time 0.1 min\n",
            "778: done 21 games, reward 2.857, eps 0.98, speed 253.72 f/s, time 0.1 min\n",
            "807: done 22 games, reward 2.727, eps 0.98, speed 335.06 f/s, time 0.1 min\n",
            "822: done 23 games, reward 2.696, eps 0.98, speed 313.09 f/s, time 0.1 min\n",
            "852: done 24 games, reward 2.708, eps 0.98, speed 315.60 f/s, time 0.1 min\n",
            "893: done 25 games, reward 2.680, eps 0.98, speed 355.63 f/s, time 0.1 min\n",
            "948: done 26 games, reward 2.654, eps 0.98, speed 317.61 f/s, time 0.1 min\n",
            "1000: done 27 games, reward 2.741, eps 0.98, speed 327.99 f/s, time 0.1 min\n",
            "1032: done 28 games, reward 2.679, eps 0.98, speed 325.44 f/s, time 0.1 min\n",
            "1052: done 29 games, reward 2.655, eps 0.98, speed 334.52 f/s, time 0.1 min\n",
            "1089: done 30 games, reward 2.600, eps 0.98, speed 325.77 f/s, time 0.1 min\n",
            "1156: done 31 games, reward 2.677, eps 0.98, speed 349.53 f/s, time 0.1 min\n",
            "1203: done 32 games, reward 2.812, eps 0.98, speed 361.96 f/s, time 0.1 min\n",
            "1253: done 33 games, reward 2.818, eps 0.97, speed 309.31 f/s, time 0.1 min\n",
            "1396: done 34 games, reward 3.147, eps 0.97, speed 358.66 f/s, time 0.1 min\n",
            "1409: done 35 games, reward 3.086, eps 0.97, speed 330.34 f/s, time 0.1 min\n",
            "1448: done 36 games, reward 3.139, eps 0.97, speed 363.87 f/s, time 0.1 min\n",
            "1510: done 37 games, reward 3.108, eps 0.97, speed 342.13 f/s, time 0.1 min\n",
            "1598: done 38 games, reward 3.211, eps 0.97, speed 373.67 f/s, time 0.1 min\n",
            "1619: done 39 games, reward 3.205, eps 0.97, speed 225.44 f/s, time 0.1 min\n",
            "1635: done 40 games, reward 3.125, eps 0.97, speed 242.14 f/s, time 0.1 min\n",
            "1690: done 41 games, reward 3.146, eps 0.97, speed 360.64 f/s, time 0.1 min\n",
            "1728: done 42 games, reward 3.167, eps 0.97, speed 311.74 f/s, time 0.1 min\n",
            "1775: done 43 games, reward 3.233, eps 0.96, speed 350.41 f/s, time 0.2 min\n",
            "1813: done 44 games, reward 3.227, eps 0.96, speed 350.71 f/s, time 0.2 min\n",
            "1844: done 45 games, reward 3.200, eps 0.96, speed 290.68 f/s, time 0.2 min\n",
            "1911: done 46 games, reward 3.196, eps 0.96, speed 364.49 f/s, time 0.2 min\n",
            "1928: done 47 games, reward 3.170, eps 0.96, speed 315.29 f/s, time 0.2 min\n",
            "2029: done 48 games, reward 3.375, eps 0.96, speed 247.98 f/s, time 0.2 min\n",
            "2090: done 49 games, reward 3.429, eps 0.96, speed 147.29 f/s, time 0.2 min\n",
            "2122: done 50 games, reward 3.360, eps 0.96, speed 117.55 f/s, time 0.2 min\n",
            "2192: done 51 games, reward 3.451, eps 0.96, speed 131.24 f/s, time 0.2 min\n",
            "2212: done 52 games, reward 3.385, eps 0.96, speed 141.47 f/s, time 0.2 min\n",
            "2259: done 53 games, reward 3.415, eps 0.95, speed 143.81 f/s, time 0.2 min\n",
            "2276: done 54 games, reward 3.352, eps 0.95, speed 106.72 f/s, time 0.2 min\n",
            "2294: done 55 games, reward 3.327, eps 0.95, speed 133.07 f/s, time 0.2 min\n",
            "2309: done 56 games, reward 3.286, eps 0.95, speed 136.20 f/s, time 0.2 min\n",
            "2334: done 57 games, reward 3.316, eps 0.95, speed 122.54 f/s, time 0.2 min\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4174583524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mloss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3469365872.py\u001b[0m in \u001b[0;36mcalc_loss\u001b[0;34m(batch, net, tgt_net, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mExperience\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_net\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstates_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mstate_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mnext_state_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3180261785.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "from IPython.display import Video, display\n",
        "\n",
        "# Collect candidate folders\n",
        "candidates = set()\n",
        "for base in [\".\", \"/content\"]:\n",
        "    candidates.update([p for p in glob.glob(os.path.join(base, \"videos*\")) if os.path.isdir(p)])\n",
        "\n",
        "# Add common folders explicitly (covers both relative and absolute paths)\n",
        "candidates.update([\n",
        "    \"videos\", \"videos_early\", \"videos_late\", \"videos_late_quick\",\n",
        "    \"videos_ckpts\", \"videos_bc\", \"videos_compare\"\n",
        "])\n",
        "\n",
        "# Normalize / dedupe / keep only existing\n",
        "folders = sorted(set(os.path.abspath(p) for p in candidates if os.path.isdir(p)))\n",
        "\n",
        "if not folders:\n",
        "    print(\"No video folders found.\")\n",
        "else:\n",
        "    for folder in folders:\n",
        "        mp4s = sorted(glob.glob(os.path.join(folder, \"*.mp4\")))\n",
        "        print(f\"\\n=== {folder} ({len(mp4s)} file(s)) ===\")\n",
        "        if not mp4s:\n",
        "            print(\"  (no mp4 files)\")\n",
        "            continue\n",
        "        for vp in mp4s:\n",
        "            print(\"ðŸ“¹\", vp)\n",
        "            display(Video(vp, embed=True, html_attributes=\"controls\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "gG2QazFQoTZs",
        "outputId": "e65eb6a4-93c9-45f7-ba84-ce76bab69e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== /content/videos_early (1 file(s)) ===\n",
            "ðŸ“¹ /content/videos_early/early_f000028-episode-0.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== /content/videos_late_quick (1 file(s)) ===\n",
            "ðŸ“¹ /content/videos_late_quick/late_quick-episode-0.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}